{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Song Popularity EDA\"\n",
    "\n",
    "- toc: true\n",
    "- branch: master\n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [Kaggle]\n",
    "- image: images/posts/song_prediction.png\n",
    "- hide: false\n",
    "- search_exclude: false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Python notebook is the Python version of [Song Popularity EDA - Live Coding Fun](https://www.kaggle.com/headsortails/song-popularity-eda-live-coding-fun) by [Martin Henze](https://www.kaggle.com/headsortails)\n",
    "\n",
    "Purpose of this notebook is to recreate the plots in python for learning purpose.\n",
    "\n",
    "The recording of the live-coding session can be found on Abhishek Thakur's YouTube channel:\n",
    "* [Song Popularity Prediction - EDA (Part 1)](https://www.youtube.com/watch?v=JXF-7rCcR1c)\n",
    "* [Song Popularity Prediction - EDA (Part 2)](https://www.youtube.com/watch?v=2aE6SvCVOis)\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "The competition is about Song Prediction based on a set of different features. The dataset contains the basic file such as `train.csv`, `test.csv` and `submission_sample.csv`. The dataset used in this competition is in tabular format. The evaluation metric used for this competition is AUC score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preparation\n",
    "\n",
    "Initially we'll load different libraries used in our analysis. Also, load the train and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-01-28T00:10:48.658705Z",
     "iopub.status.busy": "2022-01-28T00:10:48.658417Z",
     "iopub.status.idle": "2022-01-28T00:10:51.803834Z",
     "shell.execute_reply": "2022-01-28T00:10:51.803216Z",
     "shell.execute_reply.started": "2022-01-28T00:10:48.658674Z"
    }
   },
   "outputs": [],
   "source": [
    "#collapse-hide\n",
    "\"\"\"Load the libraries\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "from plotnine import *\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-28T00:10:51.806140Z",
     "iopub.status.busy": "2022-01-28T00:10:51.805655Z",
     "iopub.status.idle": "2022-01-28T00:10:52.101855Z",
     "shell.execute_reply": "2022-01-28T00:10:52.101245Z",
     "shell.execute_reply.started": "2022-01-28T00:10:51.806097Z"
    }
   },
   "outputs": [],
   "source": [
    "#collapse-hide\n",
    "\"\"\"Load the data\"\"\"\n",
    "train = pd.read_csv(\"/kaggle/input/song-popularity-prediction/train.csv\")\n",
    "test = pd.read_csv(\"/kaggle/input/song-popularity-prediction/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Overview: structure and data content\n",
    "\n",
    "The first step we'll do is look at the raw data. This tell us about the different features in the dataset, missing values, and types of features (numeric, string, categorical, etc.).\n",
    "\n",
    "### 3.1. Look at the data\n",
    "\n",
    "Let's look at the basic structure of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-28T00:10:52.103953Z",
     "iopub.status.busy": "2022-01-28T00:10:52.103064Z",
     "iopub.status.idle": "2022-01-28T00:10:52.132996Z",
     "shell.execute_reply": "2022-01-28T00:10:52.132224Z",
     "shell.execute_reply.started": "2022-01-28T00:10:52.103915Z"
    }
   },
   "outputs": [],
   "source": [
    "#collapse-hide\n",
    "print('\\nInformation about Data')\n",
    "display(train.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find:\n",
    "* There are 40000 entries and 15 features in total.\n",
    "* All the column data type is either int or float i.e. all the columns are numeric. This make is comparatively easier to work with compared to columns contains string type data.\n",
    "* We can also observe there are columns that contain less than 40K Non-Null values which indicates missing values in the dataset.\n",
    "\n",
    "Let's now look at the top 20 rows of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-28T00:10:52.135009Z",
     "iopub.status.busy": "2022-01-28T00:10:52.134791Z",
     "iopub.status.idle": "2022-01-28T00:10:52.213811Z",
     "shell.execute_reply": "2022-01-28T00:10:52.213220Z",
     "shell.execute_reply.started": "2022-01-28T00:10:52.134981Z"
    }
   },
   "outputs": [],
   "source": [
    "#collapse-hide\n",
    "\"\"\"Display top 20 rows of the train data\"\"\"\n",
    "display(train.head(20).style.set_caption(\"First Twenty rows of Training Data\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find:\n",
    "* There are missing values that can be seen as `nan` in the table above\n",
    "* The `id` column seems to have values in increasing order\n",
    "* The values in the features are in different scales\n",
    "\n",
    "Now, let's look at some basic statistics about our features in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-28T00:10:52.215458Z",
     "iopub.status.busy": "2022-01-28T00:10:52.214815Z",
     "iopub.status.idle": "2022-01-28T00:10:52.278722Z",
     "shell.execute_reply": "2022-01-28T00:10:52.277741Z",
     "shell.execute_reply.started": "2022-01-28T00:10:52.215421Z"
    }
   },
   "outputs": [],
   "source": [
    "#collapse-hide\n",
    "display(train.describe().style.set_caption(\"Basic statistics about Train Data\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find:\n",
    "* Most of the features are in the range of 0 and 1\n",
    "* There are features with only negative values (`loudness`), binary features (`audio_mode`) , and seems to be categorical (`key` and `time_signature`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Missing data\n",
    "\n",
    "Now let's take a closer look at the missing values in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-28T00:10:52.280759Z",
     "iopub.status.busy": "2022-01-28T00:10:52.280004Z",
     "iopub.status.idle": "2022-01-28T00:10:52.289418Z",
     "shell.execute_reply": "2022-01-28T00:10:52.288515Z",
     "shell.execute_reply.started": "2022-01-28T00:10:52.280721Z"
    }
   },
   "outputs": [],
   "source": [
    "#collapse-hide\n",
    "\"\"\"Missing Values\"\"\"\n",
    "print(f\"Train set has {train.isnull().sum().sum()} missing values, and test set has {test.isnull().sum().sum()} missing values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-28T00:10:52.291289Z",
     "iopub.status.busy": "2022-01-28T00:10:52.290870Z",
     "iopub.status.idle": "2022-01-28T00:10:57.157425Z",
     "shell.execute_reply": "2022-01-28T00:10:57.156610Z",
     "shell.execute_reply.started": "2022-01-28T00:10:52.291226Z"
    }
   },
   "outputs": [],
   "source": [
    "#collapse-hide\n",
    "# Refrence (edited): https://datavizpyr.com/visualizing-missing-data-with-seaborn-heatmap-and-displot/\n",
    "fig = plt.figure(figsize=(18,6))\n",
    "\n",
    "sns.displot(\n",
    "    data=train.isna().melt(value_name=\"missing\"),\n",
    "    y=\"variable\",\n",
    "    hue=\"missing\",\n",
    "    multiple=\"fill\",\n",
    "    aspect=3\n",
    ")\n",
    "plt.title(\"Missing values shown using Bar plot\", fontsize=17)\n",
    "plt.ylabel(\"\")\n",
    "plt.xlabel(\"\")\n",
    "\n",
    "plt.figure(figsize=(18,10))\n",
    "sns.heatmap(train.isna().transpose())\n",
    "plt.title('Heatmap showing Missing Values in Train data', fontsize=17)\n",
    "plt.ylabel(\"\")\n",
    "plt.xlabel(\"\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-28T00:10:57.158919Z",
     "iopub.status.busy": "2022-01-28T00:10:57.158718Z",
     "iopub.status.idle": "2022-01-28T00:10:57.599318Z",
     "shell.execute_reply": "2022-01-28T00:10:57.598405Z",
     "shell.execute_reply.started": "2022-01-28T00:10:57.158893Z"
    }
   },
   "outputs": [],
   "source": [
    "#collapse-hide\n",
    "train_null = train.isna().sum().sort_values(ascending = False)\n",
    "test_null = test.isna().sum().sort_values(ascending = False)\n",
    "\n",
    "non_zero_train_values = train_null[train_null.values > 0]\n",
    "non_zero_test_values = test_null[test_null.values > 0]\n",
    "\n",
    "fig, axes = plt.subplots(1,2, figsize=(15,8))\n",
    "sns.barplot(y=non_zero_test_values.index , x=non_zero_test_values.values, ax=axes[1], palette = \"viridis\")\n",
    "sns.barplot(y=non_zero_train_values.index , x=non_zero_train_values.values, ax=axes[0], palette = \"viridis\")\n",
    "axes[0].set_title(\"Train data\", fontsize=14)\n",
    "axes[1].set_title(\"Test data\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualization - Individual Features\n",
    "\n",
    "After getting an initial idea about our features and their values, we can now dive into the visual part of the exploration. I recommend to always plot your data. Sometimes this might be challenging, e.g. because you have tons of features. In that case, you want to start at least with a subset before you run any dimensionality reduction or other tools. This step is as much about spotting issues and irregularities as it is about learning more about the shapes and distributions of your features.\n",
    "\n",
    "### 4.1. Predictor variables\n",
    "\n",
    "* In the live session, we were building this plot step by step. (Well, we got most of the way there.) It really pays off to take the time and investigate each feature separately. This is one of the most instructive steps in the EDA process, where you aim to learn how messed up your features are. No dataset is perfect. We want to figure out how severe those imperfections are, and whether we can live with them or have to address them.\n",
    "* Different kind of data types go best with different kind of visuals. My recommendation is to start out with density plots or histograms for numerical features, and with barcharts for those that are better expressed as types of categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-28T00:10:57.600841Z",
     "iopub.status.busy": "2022-01-28T00:10:57.600612Z",
     "iopub.status.idle": "2022-01-28T00:11:03.546364Z",
     "shell.execute_reply": "2022-01-28T00:11:03.545398Z",
     "shell.execute_reply.started": "2022-01-28T00:10:57.600814Z"
    }
   },
   "outputs": [],
   "source": [
    "#collapse-hide\n",
    "useful_cols = [col for col in train.columns if col not in [\"id\", \"song_popularity\"]]\n",
    "numeric_cols = [col for col in useful_cols if col not in [\"key\", \"audio_mode\", \"time_signature\"]]\n",
    "\n",
    "n_rows = 5\n",
    "n_cols = 3\n",
    "index = 1\n",
    "\n",
    "colors = [\"red\", \"darkblue\", \"green\"]\n",
    "\n",
    "fig = plt.figure(figsize=(16,20))\n",
    "\n",
    "for index, col in enumerate(train[useful_cols].columns):\n",
    "    plt.subplot(n_rows,n_cols,index+1)\n",
    "    \n",
    "    if col in numeric_cols:\n",
    "        sns.kdeplot(train[col], color=random.sample(colors, 1), fill=True)\n",
    "        plt.title(col, fontsize=14)\n",
    "        plt.xlabel(\"\")\n",
    "        plt.ylabel(\"\")\n",
    "        plt.tight_layout()\n",
    "    else:\n",
    "        sns.countplot(train[col])\n",
    "        plt.title(col, fontsize=14)\n",
    "        plt.xlabel(\"\")\n",
    "        plt.ylabel(\"\")\n",
    "        plt.tight_layout()\n",
    "\n",
    "plt.subplot(n_rows,n_cols,14)\n",
    "sns.kdeplot(np.log(train['instrumentalness']), color=random.sample(colors, 1), fill=True)\n",
    "plt.title('instrumentalness (log transformed)', fontsize=14)\n",
    "plt.ylabel(\" \")\n",
    "plt.xlabel(\" \")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find:\n",
    "* Our initial impressions of the data types have largely been confirmed: audio_mode is a boolean feature, and time_signature and key are ordinal or categorical ones (or integer; although a better understanding of those musical concepts would certainly benefit from some domain knowledge.)\n",
    "* A number of features are bounded between 0 and 1: accosticness, danceability, energy, liveliness, speechiness, and audio_valence.\n",
    "* The feature loudness looks like it refer to the decibel scale.\n",
    "* The distribution of instrumentalness is heavily right-skewed, and even after a log transform this feature doesn’t look very well-behaved. This might need a bit more work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-23T19:23:32.757062Z",
     "iopub.status.busy": "2022-01-23T19:23:32.75678Z",
     "iopub.status.idle": "2022-01-23T19:23:32.947171Z",
     "shell.execute_reply": "2022-01-23T19:23:32.946224Z",
     "shell.execute_reply.started": "2022-01-23T19:23:32.757013Z"
    }
   },
   "source": [
    "### 4.2. Target: Song Popularity\n",
    "\n",
    "On to the target itself. We figured out that song_popularity is a binary feature, and thus we can express it as boolean. Here we plot a barchart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-28T00:11:03.550387Z",
     "iopub.status.busy": "2022-01-28T00:11:03.549554Z",
     "iopub.status.idle": "2022-01-28T00:11:03.657802Z",
     "shell.execute_reply": "2022-01-28T00:11:03.656996Z",
     "shell.execute_reply.started": "2022-01-28T00:11:03.550337Z"
    }
   },
   "outputs": [],
   "source": [
    "#collapse-hide\n",
    "sns.countplot(train.song_popularity.astype(\"bool\"))\n",
    "plt.title(\"Target: Song Popularity\", fontsize=14)\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find:\n",
    "* There is a slight imbalance in the target distribution: a bit more than 60/40. Not super imbalanced, but something to keep in mind."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature interactions\n",
    "\n",
    "After learning more about each individual feature, we now want to see them interacting with one another. It’s best to perfom those steps in that order, so that you can understand and interpret the interactions in the context of the overall distributions.\n",
    "\n",
    "### 5.1. Target impact\n",
    "\n",
    "We have seen all the feature distributions, now we want to investigate whether they look different based on the target value. Here’s an example for song_duration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-28T00:11:03.660025Z",
     "iopub.status.busy": "2022-01-28T00:11:03.659396Z",
     "iopub.status.idle": "2022-01-28T00:11:08.907864Z",
     "shell.execute_reply": "2022-01-28T00:11:08.906950Z",
     "shell.execute_reply.started": "2022-01-28T00:11:03.659978Z"
    }
   },
   "outputs": [],
   "source": [
    "#collapse-hide\n",
    "fig = plt.figure(figsize=(16,18))\n",
    "n_rows = 4\n",
    "n_cols = 3\n",
    "\n",
    "for index, col in enumerate(numeric_cols):\n",
    "    plt.subplot(n_rows, n_cols, index+1)\n",
    "    \n",
    "    sns.kdeplot(train[col], hue=train.song_popularity.astype(\"bool\"), fill=True)\n",
    "    plt.title(col, fontsize=14)\n",
    "    plt.xlabel(\"\")\n",
    "    plt.ylabel(\"\")\n",
    "    plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "* By looking at the probability distribution of different variables we find that popular songs are almost exactly the same length as unpopular ones. There is a slight difference, but it’s pretty small.\n",
    "\n",
    "Now we can check the categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-28T00:11:08.910040Z",
     "iopub.status.busy": "2022-01-28T00:11:08.909549Z",
     "iopub.status.idle": "2022-01-28T00:11:09.613448Z",
     "shell.execute_reply": "2022-01-28T00:11:09.612457Z",
     "shell.execute_reply.started": "2022-01-28T00:11:08.909995Z"
    }
   },
   "outputs": [],
   "source": [
    "#collapse-hide\n",
    "fig = plt.figure(figsize=(18,5))\n",
    "\n",
    "for index, col in enumerate([\"key\", \"audio_mode\", \"time_signature\"]):\n",
    "    plt.subplot(1,3,index+1)\n",
    "    \n",
    "    sns.countplot(train[col], hue=train.song_popularity.astype(\"bool\"))\n",
    "    plt.title(col, fontsize=14)\n",
    "    plt.xlabel(\"\")\n",
    "    plt.ylabel(\"\")\n",
    "    plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Feature Interaction\n",
    "\n",
    "How do the predictor features interact with each other? Are there any redundancies or strong relationships? We will start out with a correlation matrix, and then look at features of interest in a bit more detail.\n",
    "\n",
    "#### 5.2.1. Correlations overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-28T00:11:09.615457Z",
     "iopub.status.busy": "2022-01-28T00:11:09.614975Z",
     "iopub.status.idle": "2022-01-28T00:11:09.639256Z",
     "shell.execute_reply": "2022-01-28T00:11:09.638525Z",
     "shell.execute_reply.started": "2022-01-28T00:11:09.615408Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#collapse-hide\n",
    "# Refrence (edited): https://towardsdatascience.com/better-heatmaps-and-correlation-matrix-plots-in-python-41445d0f2bec\n",
    "def heatmap(data):\n",
    "    corr = pd.melt(data.reset_index(), id_vars='index') # Unpivot the dataframe, so we can get pair of arrays for x and y\n",
    "    corr.columns = ['x', 'y', 'value']\n",
    "    x=corr['x']\n",
    "    y=corr['y']\n",
    "    size=corr['value'].abs()\n",
    "    color=corr['value']\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10,10))\n",
    "    plot_grid = plt.GridSpec(1, 15, hspace=0.2, wspace=0.1) # Setup a 1x15 grid\n",
    "    ax = plt.subplot(plot_grid[:,:-1]) # Use the leftmost 14 columns of the grid for the main plot\n",
    "    \n",
    "    n_colors = 256 # Use 256 colors for the diverging color palette\n",
    "    palette = sns.diverging_palette(20, 220, n=n_colors) # Create the palette\n",
    "    color_min, color_max = [-1, 1] # Range of values that will be mapped to the palette, i.e. min and max possible correlation\n",
    "    size_min, size_max = 0, 1\n",
    "    \n",
    "    def value_to_color(val):\n",
    "        val_position = float((val - color_min)) / (color_max - color_min) # position of value in the input range, relative to the length of the input range\n",
    "        val_position = min(max(val_position, 0), 1) # bound the position betwen 0 and 1\n",
    "        ind = int(val_position * (n_colors - 1)) # target index in the color palette\n",
    "        return palette[ind]\n",
    "    \n",
    "    def value_to_size(val):\n",
    "        val_position = (val - size_min) * 0.99 / (size_max - size_min) + 0.01 # position of value in the input range, relative to the length of the input range\n",
    "        val_position = min(max(val_position, 0), 1) # bound the position betwen 0 and 1\n",
    "        return val_position * size_scale\n",
    "        \n",
    "    # Mapping from column names to integer coordinates\n",
    "    x_labels = [v for v in sorted(x.unique())]\n",
    "    y_labels = [v for v in sorted(y.unique())]\n",
    "    x_to_num = {p[1]:p[0] for p in enumerate(x_labels)} \n",
    "    y_to_num = {p[1]:p[0] for p in enumerate(y_labels)} \n",
    "    \n",
    "    size_scale = 500\n",
    "    ax.scatter(\n",
    "        x=x.map(x_to_num), # Use mapping for x\n",
    "        y=y.map(y_to_num), # Use mapping for y\n",
    "        s=size.apply(value_to_size), # Vector of square sizes, proportional to size parameter\n",
    "        c=color.apply(value_to_color), # Vector of square color values, mapped to color palette\n",
    "        marker='s' # Use square as scatterplot marker\n",
    "    )\n",
    "    \n",
    "    # Show column labels on the axes\n",
    "    ax.set_xticks([x_to_num[v] for v in x_labels])\n",
    "    ax.set_xticklabels(x_labels, rotation=45, horizontalalignment='right')\n",
    "    ax.set_yticks([y_to_num[v] for v in y_labels])\n",
    "    ax.set_yticklabels(y_labels)\n",
    "    \n",
    "    ax.grid(False, 'major')\n",
    "    ax.grid(True, 'minor')\n",
    "    ax.set_xticks([t + 0.5 for t in ax.get_xticks()], minor=True)\n",
    "    ax.set_yticks([t + 0.5 for t in ax.get_yticks()], minor=True)\n",
    "        \n",
    "    ax.set_xlim([-0.5, max([v for v in x_to_num.values()]) + 0.5])\n",
    "    ax.set_ylim([-0.5, max([v for v in y_to_num.values()]) + 0.5])\n",
    "    ax.set_facecolor('#F1F1F1')\n",
    "    \n",
    "    # Add color legend on the right side of the plot\n",
    "    ax = plt.subplot(plot_grid[:,-1]) # Use the rightmost column of the plot\n",
    "\n",
    "    col_x = [0]*len(palette) # Fixed x coordinate for the bars\n",
    "    bar_y=np.linspace(color_min, color_max, n_colors) # y coordinates for each of the n_colors bars\n",
    "\n",
    "    bar_height = bar_y[1] - bar_y[0]\n",
    "    ax.barh(\n",
    "        y=bar_y,\n",
    "        width=[5]*len(palette), # Make bars 5 units wide\n",
    "        left=col_x, # Make bars start at 0\n",
    "        height=bar_height,\n",
    "        color=palette,\n",
    "        linewidth=0\n",
    "    )\n",
    "    ax.set_xlim(1, 2) # Bars are going from 0 to 5, so lets crop the plot somewhere in the middle\n",
    "    ax.grid(False) # Hide grid\n",
    "    ax.set_facecolor('white') # Make background white\n",
    "    ax.set_xticks([]) # Remove horizontal ticks\n",
    "    ax.set_yticks(np.linspace(min(bar_y), max(bar_y), 3)) # Show vertical ticks for min, middle and max\n",
    "    ax.yaxis.tick_right() # Show vertical ticks on the right\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-28T00:11:09.640856Z",
     "iopub.status.busy": "2022-01-28T00:11:09.640431Z",
     "iopub.status.idle": "2022-01-28T00:11:10.812978Z",
     "shell.execute_reply": "2022-01-28T00:11:10.812113Z",
     "shell.execute_reply.started": "2022-01-28T00:11:09.640819Z"
    }
   },
   "outputs": [],
   "source": [
    "#collapse-hide\n",
    "heatmap(train[numeric_cols].corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T05:39:46.935989Z",
     "iopub.status.busy": "2022-01-27T05:39:46.935247Z",
     "iopub.status.idle": "2022-01-27T05:39:46.958183Z",
     "shell.execute_reply": "2022-01-27T05:39:46.957285Z",
     "shell.execute_reply.started": "2022-01-27T05:39:46.935951Z"
    }
   },
   "source": [
    "Below is a similar correlation heatmap but only using the lower triangle to show the correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-28T00:11:10.815237Z",
     "iopub.status.busy": "2022-01-28T00:11:10.814340Z",
     "iopub.status.idle": "2022-01-28T00:11:11.409939Z",
     "shell.execute_reply": "2022-01-28T00:11:11.409147Z",
     "shell.execute_reply.started": "2022-01-28T00:11:10.815169Z"
    }
   },
   "outputs": [],
   "source": [
    "#collapse-hide\n",
    "# Refrence (edited): https://medium.com/@szabo.bibor/how-to-create-a-seaborn-correlation-heatmap-in-python-834c0686b88e\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "matrix = np.triu(np.ones_like(train[numeric_cols].corr(), dtype=np.bool))\n",
    "sns.heatmap(train[numeric_cols].corr(), mask=matrix, vmin=-1, vmax=1, annot=True, cmap=sns.diverging_palette(220, 20, as_cmap=True))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find:\n",
    "* There’s a strong anti-correlation between `acousticness` vs `energy` and `loudness`, respectively. Consequently, `energy` and `loudness` share a strong correlation.\n",
    "* None of the features individually show a notable correlation with the target `song_popularity`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.2. Categorical feature interactions\n",
    "\n",
    "Whenever we’re looking at categorical features, we can assign a visualisation dimension like colour, size, or facets to those. We will start modifying our trusted density plots to look at the distributions of energy (potentially one of the more interesting numerical features) for the different values of time_signature (here encoded as colour):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-28T00:11:11.411229Z",
     "iopub.status.busy": "2022-01-28T00:11:11.411007Z",
     "iopub.status.idle": "2022-01-28T00:11:11.957076Z",
     "shell.execute_reply": "2022-01-28T00:11:11.956204Z",
     "shell.execute_reply.started": "2022-01-28T00:11:11.411202Z"
    }
   },
   "outputs": [],
   "source": [
    "#collapse-hide\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "sns.kdeplot(x=\"energy\", hue=\"time_signature\", data=train, fill=True, bw=0.03)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-28T00:21:14.097337Z",
     "iopub.status.busy": "2022-01-28T00:21:14.097043Z",
     "iopub.status.idle": "2022-01-28T00:21:21.091872Z",
     "shell.execute_reply": "2022-01-28T00:21:21.091058Z",
     "shell.execute_reply.started": "2022-01-28T00:21:14.097309Z"
    }
   },
   "outputs": [],
   "source": [
    "#collapse-hide\n",
    "(ggplot(train, aes(\"key\", \"time_signature\", fill = \"energy\")) \n",
    " + geom_tile()\n",
    " + theme(figure_size=(16,5))\n",
    " + scale_x_continuous(breaks=range(0,12)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find:\n",
    "\n",
    "* For time_signatures 2 and 5 we have no instances of key == 11. This is no big surprise, since those three values are already rare individually, which makes their combinations even more rare.\n",
    "\n",
    "* There are no clear clusters of high vs low energy features here.\n",
    "\n",
    "* We can see certain combinations that are particularly low energy, such as key == 2 and time_signature == 1 or 8. key == 3 and time_signature == 1 seems to be a particularly energetic combination.\n",
    "\n",
    "\n",
    "### 5.3. Feature Target Interaction\n",
    "\n",
    "Once we have found interesting correlations we can look for clustering in the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-28T00:21:27.895709Z",
     "iopub.status.busy": "2022-01-28T00:21:27.895394Z",
     "iopub.status.idle": "2022-01-28T00:21:34.964264Z",
     "shell.execute_reply": "2022-01-28T00:21:34.963326Z",
     "shell.execute_reply.started": "2022-01-28T00:21:27.895677Z"
    }
   },
   "outputs": [],
   "source": [
    "#collapse-hide\n",
    "(ggplot(train, aes('key', 'time_signature')) \n",
    " + geom_tile(aes(fill='energy')) \n",
    " + facet_wrap(\"song_popularity\", nrow = 2) \n",
    " + theme_minimal() \n",
    " + theme(figure_size=(16, 8))\n",
    " + scale_x_continuous(breaks=range(0,12)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-28T00:11:25.660362Z",
     "iopub.status.busy": "2022-01-28T00:11:25.658965Z",
     "iopub.status.idle": "2022-01-28T00:11:46.516888Z",
     "shell.execute_reply": "2022-01-28T00:11:46.516264Z",
     "shell.execute_reply.started": "2022-01-28T00:11:25.660315Z"
    }
   },
   "outputs": [],
   "source": [
    "#collapse-hide\n",
    "sns.displot(data=train, x=\"energy\", y=\"audio_valence\", col=\"song_popularity\", kind=\"kde\", fill=True, legend=True, height=8, aspect=0.75)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-28T00:35:00.755852Z",
     "iopub.status.busy": "2022-01-28T00:35:00.755578Z",
     "iopub.status.idle": "2022-01-28T00:35:03.067811Z",
     "shell.execute_reply": "2022-01-28T00:35:03.066956Z",
     "shell.execute_reply.started": "2022-01-28T00:35:00.755824Z"
    }
   },
   "outputs": [],
   "source": [
    "#collapse-hide\n",
    "fig = plt.figure(figsize=(12,6))\n",
    "sns.scatterplot(x=\"energy\", y=\"acousticness\", hue=\"song_popularity\", data=train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T21:41:23.933066Z",
     "iopub.status.busy": "2022-01-27T21:41:23.932778Z",
     "iopub.status.idle": "2022-01-27T21:41:23.939378Z",
     "shell.execute_reply": "2022-01-27T21:41:23.938279Z",
     "shell.execute_reply.started": "2022-01-27T21:41:23.933034Z"
    }
   },
   "source": [
    "### More Resources:\n",
    "* [Choosing different color palette in Seaborn](https://seaborn.pydata.org/tutorial/color_palettes.html#palette-tutorial)\n",
    "* See also\n",
    "    * [PairGrid](https://seaborn.pydata.org/generated/seaborn.PairGrid.html#seaborn.PairGrid): Subplot grid for plotting pairwise relationships\n",
    "    * [relplot](https://seaborn.pydata.org/generated/seaborn.relplot.html#seaborn.relplot): Combine a relational plot and a FacetGrid\n",
    "    * [displot](https://seaborn.pydata.org/generated/seaborn.displot.html#seaborn.displot): Combine a distribution plot and a FacetGrid\n",
    "    * [catplot](https://seaborn.pydata.org/generated/seaborn.catplot.html#seaborn.catplot): Combine a categorical plot and a FacetGrid\n",
    "    * [lmplot](https://seaborn.pydata.org/generated/seaborn.lmplot.html#seaborn.lmplot): Combine a regression plot and a FacetGrid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Special Thanks to [Martin Henze](https://www.kaggle.com/headsortails) for sharing his knowledge during the live coding session. Also, thank you [Abhishek Thakur](https://www.kaggle.com/abhishek) for hosting these wonderful sessions for people to learn. I look forward to learn more.\n",
    "\n",
    "Share if you liked it, comment if you loved it. Hope to see you guys in the next one. Peace!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
