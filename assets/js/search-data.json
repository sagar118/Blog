{
  
    
        "post0": {
            "title": "What is Natural Language Processing?",
            "content": "Natural language processing is a branch of Artificial Intelligence which aims to bridge the gap between how a computer and human communicate with each other. The two major handles used for communication are speech and written i.e. text. . History of Natural Language Processing: . The dawn of NLP can be dated back to the early 1900s. In 1950, Alan Turing published his famous article “Computing Machinery and Intelligence” which proposed what is now called the Turing test as a criterion of intelligence. It tests the ability of the computer program to impersonate a human in a real-time conversation with a human judge where the judge is unable to distinguish the human from the computer program. In 1954, the Georgetown experiment automatically translated more than sixty Russian words into English. . In 1957, Noam Chomsky’s Syntactic Structures a rule-based system of syntactic structures with “universal grammar” was an incredible advancement. Up to the 1980’s most of the NLP systems were based on complex hand-written rules but in the late 1980s by the introduction of machine learning algorithms for language processing revolutionized the field. A steady increase in computational power resulting from Moore’s law and use of statistical models that use probabilistic measures to map the features making up the input data. Watson an artificial intelligence software designed as a question answering system won the Jeopardy contest, defeating the best human players in February 2011. . Development of famous virtual assistants like Siri in 2011, Amazon Alexa in 2014, and Google Assistant in 2016. The use of deep learning produced better results than the state-of-the-art in many natural language processing tasks, such as machine translation, text classification, and many more. Recent advancements include the use of network architecture of the transformer which is based on the attention mechanism that has produced better results in various NLP tasks. . We humans in our daily life overlook the powerful ability of our human brain to read, understand the meaning of a word, it’s context (how does it relate to each other), understand humor, sarcasm, and thousand other things. How do we teach this to a computer? . Challenges in Natural language processing: . 1. Ambiguity: In a natural language, words are unique but their meaning may differ based on the context in which it is used. One classical example used is: . The bank is a financial institution where customers can save or borrow money. | Tom was sitting by the banks of the river. | . In this example, we can see that the word “bank” is used in two different ways. The word is the same but the meaning is different. This is because the context in which the word is used is different. . 2. Co-Referencing: It is a process to find all the phrases in the document that refer to the same entity. Example: Harry kept the paneer on the plate and ate it. Here it refers to the paneer that he ate which was kept on the plate. . 3. Information Extraction: Identifying phrases in a language that refer to specific types of entities and relations in text. Named Entity Recognition (NER) is the task used to identify the names of people, organizations, places, etc, in a text. Example: Tom used to work at FedEx and lives in Mumbai, India. where Person = Tom, organization = FedEx and Place = Mumbai, India . 4. Personality, intention, emotions, and style: Different authors may have different personalities, intentions, emotions, and styles to convey the same idea. Based on these factors the underlying idea can be interpreted in different ways. Use of humor or sarcasm may convey a meaning that is opposite of the literal one. . Applications: . 1. Machine Translation: The idea behind machine translation is to develop a system that is capable of translating text from one language to another without any human intervention. Only translating the text from one language to another is not the key. Understanding the meaning behind the text and translating it to some other language is the crux of it. Example: Google Translate . 2. Automatic summarization: We all love to read storybooks and always a good storybook will have a summary at the end that highlights the important things about the story. Likewise take any piece of text, a story, a news article, etc, and develop a system that can automatically summary the piece of text. Example: Inshorts – an app that summarizes each news article in 60 words. . 3. Sentiment Analysis: It deals with the study of extracting opinions and sentiment that are not always explicitly expressed. For instance it helps the company to understand the level of consumer satisfaction for its goods and services. Example: “I love the new iPhone and it has a great camera.”. . Another branch of sentiment analysis is “Aspect based Sentiment Analysis” where it tries to extract opinions for each aspect from the customer review. Example: “The new iPhone is great it has a great camera but the battery life is not that good.” Here the customer is satisfied with the camera aspect of the iPhone but not the battery life. . 4. Text Classification: Organizing text documents into predefined categories enables to classify the information or any activity. Examples: Classifying an email as spam or not spam. . 5. Question Answering: Question answering deals with a system that can answer questions posed by humans in natural language. Sounds simple yet building the knowledge base, understanding the text, and to answer in natural language is altogether a thing in itself. . 6. Chatbots: Chatbots are a piece of software that can simulate a conversation (or chat) with a user in natural language through websites, apps, messaging applications, etc. Chatbots are a natural evolution of question answering system but are one step further with their ability to understand the text and engage in a conversation. . 7. Speech Recognition: Using our voice to interact with our phones has become a common phenomenon. For example to ask questions to our voice assistants like Google Assistant/Siri/Cortana, use of voice to type a piece of text. Recognizing speech has replaced the method by which we interact with our devices and made it so convenient. . Recent advancements in NLP have deepened our knowledge on how to tackle the various challenges in NLP. Also, this new decade will be filled with excitement and breakthroughs that awaits us. Stay tunned to deep dive into the world of NLP. . Share if you like it, comment if you loved it. Hope to see you guys in the next one. Peace! .",
            "url": "https://sagar118.github.io/blog/machine%20learning/natural%20language%20processing/nlp/2021/04/05/What-is-NLP.html",
            "relUrl": "/machine%20learning/natural%20language%20processing/nlp/2021/04/05/What-is-NLP.html",
            "date": " • Apr 5, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Path to become a Machine Learning Expert",
            "content": "Path to becoming a Machine Learning (ML) Expert made easy. There are a lot of resources out there that can be overwhelming at the start. But don’t worry this learning path would provide structure and lay the foundational knowledge to begin a career in ML. . 1. Learn the basics of Descriptive Statistics, Inferential Statistics and Math used in Machine Learning . Understanding the math used in ML can help in building the foundation strong. Udacity offers courses on descriptive statistics and inferential statistics. These courses are free and use excel to teach the concepts. . Along with statistics and probabilities, concepts on linear algebra, multivariate calculus, optimization functions and many more form the building blocks for ML. There is an awesome youtube channel that makes these concepts very easy to learn. 3Brown1Blue focuses on teaching mathematics using a distinct visual perspective. . More resources: . Computational Linear Algebra for Coders | Prof. Gilbert Strang’s Linear Algebra book/course | Matrix Cookbook by Kaare Brandt Petersen &amp; Michael Syskind Pedersen | Think Stats (Exploratory Data Analysis in Python) by Allen Downey | Convex Optimization by Stephen Boyd and Lieven Vandenberghe | Essentials of Metaheuristics by Sean Luke | . 2. Learn the basics of Python and it&#8217;s packages . First, let’s install Python. The easiest way to do this is by installing Anaconda. All the packages that are required come along with Anaconda. . You can start from learning the basics of Python i.e. data structures, functions, class, etc. and it’s libraries. I started learning about python in my college days, I read the book Learn Python the Hard Way. A very good book for beginners. Introduction to Python Programming by Udacity is a free course that covers the basics of Python. Introduction to Python is another free course by Analytics Vidhya. Another free course by Google is Google’s Python Class. . Next, learn about how to use Regular Expression (also called regex) in Python. It will come in use for data cleaning, especially if you are working with text data. Learn regular expressions through Google class. A very good beginner tutorial for learning regular expression in python on Analytics Vidhya. Cheatsheet for Regex. . Now comes the fun part of learning the various libraries in Python. Numpy, Pandas, Matplotlib, Seaborn, and Sklearn are the packages heavily used in ML. . Numpy provides a high-performance multidimensional array and basic tools to compute with and manipulate these arrays. Numpy quickstart tutorial is a good place to start. This will form a good foundation for this to come. Practice numpy by solving 100 numpy exercises to solve. | Pandas is used for data manipulation and analysis. The most used package in Python is Pandas. Intro to pandas data structure provides a detailed tutorial on pandas. A short course by Kaggle on pandas. | Matplotlib is a visualization library in python. In the matplotlib tutorial, you will learn the basics of Python data visualization, the anatomy of a Matplotlib plot, and much more. Official documentation of matplotlib is one of the best ways to learn the library. | Seaborn is another visualization library built on top of matplotlib. Kaggle short course on data visualization provides a good start point to learn the library. | . 3. Data Exploration/Cleaning/Preparation . Real-world data is unstructured, contains missing values, outliers, typos, etc. This step is one of the most important steps for a data analyst to perform because how good the model will perform will depend on the quality of the data. . Learn different stages of data explorations: . Variable Identification, Univariate and Multivariate analysis | Missing values treatment | Outlier treatment | Feature Engineering | Additional resources: . You can also refer to the data exploration guide. | Book on Python for Data Analysis.pdf) by Wes McKinney | . 4. Introduction to Machine Learning . Now it’s time to enter the belly of the beast. There are various resources to learn ML and I would suggest the following courses: . Machine Learning by Stanford (Coursera) The Machine Learning course by Andrew Ng is one of the best courses out there and covers all the basic algorithms. Also, it introduces all the advanced topics in a very simple manner which is easy to understand. However, this course is taught in Octave rather than the popular languages like R/Python. Also, this course is NOT free but you can apply for financial aid. . | Machine Learning A-Z™: Hands-On Python &amp; R In Data Science (Udemy) Good course for beginners. Explore complex topics such as natural language processing (NLP), reinforcement learning (RL), deep learning (DL) among many others. Tons of practice exercise and quizzes. This course is NOT free but comparatively not expensive. . | Machine Learning (edx) This is an advanced course that has the highest math prerequisite out of any other course in this list. You’ll need a very firm grasp of Linear Algebra, Calculus, Probability, and programming. This course is free of cost but to acquire a certificate payment is required. . | Comprehensive learning path for Data Science (Analytics Vidhya) This course covers every topic right from the beginning. Installing Python, data cleaning and preparation, Machine learning concepts, deep learning, and NLP. This course is free and does not come with any certification. . | Books: . The Hundred Page Machine Learning Book | The Elements of Statistical Learning: Data Mining, Inference, and Prediction, Second Edition | List of best books for machine learning. . After learning about the various techniques in ML the next natural thing to do is apply those techniques. What better place than Kaggle. It is one of the most popular websites among data science enthusiasts. Below two problem statement can be a good starting problem statement to begin with. . Titanic: Machine Learning from Disaster | House Prices: Advanced Regression Techniques | 5. Deep Learning . Using the idea to mimic a human brain has been around since the 1900s. There were various algorithms and techniques developed for the same but due to the lack of computing power, it was difficult to run those algorithms. . Due to the improvements in the hardware and the introduction to using GPUs to compute caught the attention of people passionate about working on neural net-based models. Today, state of the art results can be obtained using deep neural networks. . Courses from deeplearning.ai on Coursera are one of the most popular and fantastic courses on deep learning. . Neural Networks and Deep Learning | Deep Learning Specialization | Both the courses are paid but financial aid is available for both of them. . Additional Resources: . Deep Learning Summer School, Montreal 2015 | Deep Learning for Perception, Virginia Tech, Electrical, and Computer Engineering | CS231N 2017 | A blog that explains concepts on Convolutional Neural Nets (CNN) | (Book) Deep Learning – Methods and Applications | (Youtube Channel) DeepLearning.TV | Deep Learning book from MIT | Neural Networks and Deep Learning online Book | Comprehensive resources on deeplearning.net | 6. Natural Language Processing . Natural language processing (NLP) is a branch of Artificial Intelligence which aims to bridge the gap between how a computer and human communicate with each other. The two major handles used for communication are speech and written i.e. text. If you are unfamiliar with what NLP is, this blog could help in understanding what NLP is. . Courses: . (Youtube) Natural Language Processing | University of Michigan | Speech and Language Processing | Stanford CS224N: NLP with Deep Learning | Winter 2019 – Stanford | Lecture Collection | Natural Language Processing with Deep Learning (Winter 2017) – Stanford | CS224d: Deep Learning for Natural Language Processing – Stanford | Natural Language Processing Specialization offered by deeplearning.ai on Coursera (Intermediate level) | Natural Language Processing offered by National Research University Higher School of Economics on Coursera (Advanced level course) | Machine Learning in itself is a huge domain and the only way to master it is to explore and practice. I cannot stress more on practice because without practice is like trying to play the guitar without any strings. . Popular blogs to follow: . Analytics Vidhya | Machine Learning Mastery | Towards Data Science | KDnuggets | Additional Resources: . A Complete Python Tutorial to Learn Data Science from Scratch | A Comprehensive Learning Path for Deep Learning in 2019 on Analytics Vidhya | Learning Path to Master Computer Vision in 2020 on Analytics Vidhya | A Comprehensive Learning Path to Understand and Master NLP in 2020 on Analytics Vidhya | A Comprehensive Guide to Understand and Implement Text Classification in Python on Analytics Vidhya | Collection of datasets for NLP | A comprehensive Learning path to becoming a data scientist in 2020 free course on Analytics Vidhya | I wish you all the best on your journey to becoming a machine learning expert. . Share if you like it, comment if you loved it. Hope to see you guys in the next one. Peace! .",
            "url": "https://sagar118.github.io/blog/machine%20learning/learning%20path/2021/04/05/Path-to-become-a-Machine-Learning-Expert.html",
            "relUrl": "/machine%20learning/learning%20path/2021/04/05/Path-to-become-a-Machine-Learning-Expert.html",
            "date": " • Apr 5, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://sagar118.github.io/blog/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://sagar118.github.io/blog/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://sagar118.github.io/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://sagar118.github.io/blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}